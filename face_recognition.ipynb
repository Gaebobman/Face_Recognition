{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b2b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os import makedirs\n",
    "from os.path import isdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd649d1",
   "metadata": {},
   "source": [
    "# Flow\n",
    "<ol>\n",
    "    <li>Register face if not registered  </li>\n",
    "    <li>Continue face recognition as requested by the server (Not actually implemented in this example)  </li>\n",
    "    <li>Capture and process image</li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab19347",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "Detect Face from aimage and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e00e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce591150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용안함\n",
    "\n",
    "\n",
    "# https://076923.github.io/posts/Python-opencv-2/\n",
    "# https://scribblinganything.tistory.com/472\n",
    "\n",
    "def capture():\n",
    "    capture= cv2.VideoCapture(0)    # If the webcam is not installed, the CSI Cam becomes the #0 camera\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    while True:            # wait 33ms for key input, if key input detected, break Loop\n",
    "        capture_result, frame = capture.read()        # grab() and retrieve() in one call\n",
    "        cv2.imshow(\"VideoFrame\", frame)\n",
    "        if cv2.waitKey(1) == ord('c'):\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return capture_result, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908de3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용안함\n",
    "\n",
    "# https://ai0.kr/m/41\n",
    "\n",
    "def track_faces(capture, classifier, image_scale, max_faces):\n",
    "    capture_copy = capture.copy()\n",
    "    grayscale_capture = cv2.cvtColor(capture_copy, cv2.COLOR_BGR2GRAY)    # Apply Grayscale\n",
    "    faces = classifier.detectMultiScale(grayscale_capture, image_scale, max_faces)\n",
    "\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f069c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "# function for consecutive capture\n",
    "def detect_face(frame, classifier):\n",
    "    grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(grayscale_frame, 1.3, 5)   # image, image_scale, max_faces\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6df2c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "def capture_face(user_name, classifier):\n",
    "    if not isdir(f\"data/sub_data/{user_name}\"):\n",
    "        makedirs(f\"data/sub_data/{user_name}\")\n",
    "    capture= cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        result, frame = capture.read()\n",
    "        if detect_face(frame, classifier) is not None:\n",
    "            count+=1\n",
    "            face = face = cv2.resize(detect_face(frame, classifier),(200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(f\"data/sub_data/{user_name}/user{count}.png\",face)\n",
    "            cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "            cv2.imshow('Face Cropper',face)\n",
    "        else:\n",
    "            print(\"Face not Found\")\n",
    "            pass\n",
    "        # Press Enter or get 100images to break\n",
    "        if cv2.waitKey(1)==13 or count==100:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Colleting Samples Complete!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6478996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    classifier = cv2.CascadeClassifier(\"data/haarcascade_frontalface_default.xml\")\n",
    "    capture_face(\"lee\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5087eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c29531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train User\n",
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "def train_face(user_name):\n",
    "    data_path = \"data/sub_data/\" + user_name+ '/'\n",
    "    face_pics = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "    training, labels = [], []\n",
    "    \n",
    "    for i, files in enumerate(face_pics):\n",
    "        image_path = data_path + face_pics[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if images is None:\n",
    "            continue    \n",
    "            \n",
    "        training.append(np.asarray(images, dtype=np.uint8))\n",
    "        labels.append(i)\n",
    "        \n",
    "    if len(labels) == 0:\n",
    "        print(\"There is no data to train.\")\n",
    "        return None\n",
    "    \n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    # 모델 생성\n",
    "    model = cv2.face.LBPHFaceRecognizer_create()\n",
    "    # 학습\n",
    "    model.train(np.asarray(training), np.asarray(labels))\n",
    "    print(name + \" : Model Training Complete!!!!!\")\n",
    "\n",
    "    #학습 모델 리턴\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ade60ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_multiple users\n",
    "def trains():\n",
    "    \n",
    "    data_path = \"data/sub_data/\"\n",
    "    # 폴더만 색출\n",
    "    model_dirs = [f for f in listdir(data_path) if isdir(join(data_path,f))]\n",
    "    \n",
    "    #학습 모델 저장할 딕셔너리\n",
    "    models = {}\n",
    "    \n",
    "    # 각 폴더에 있는 얼굴들 학습\n",
    "    for model in model_dirs:\n",
    "        \n",
    "        print('model :' + model)\n",
    "        # 학습 시작\n",
    "        result = train_face(model)\n",
    "        # 학습이 안되었다면 패스!\n",
    "        if result is None:\n",
    "            continue\n",
    "        # 학습되었으면 저장\n",
    "        print('model2 :' + model)\n",
    "        models[model] = result\n",
    "\n",
    "    # 학습된 모델 딕셔너리 리턴\n",
    "    return models    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5517539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#얼굴 검출\n",
    "def face_detector(img, size = 0.5):\n",
    "        gray_scale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray_scale,1.3,5)\n",
    "        if len(faces) == 0:\n",
    "            return img,[]\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(roi, (200,200))\n",
    "        return img,roi   #검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40802ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(models):    \n",
    "    #카메라 열기 \n",
    "    capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        #카메라로 부터 사진 한장 읽기 \n",
    "        capture_result, frame = capture.read()\n",
    "        # 얼굴 검출 시도 \n",
    "        image, face = face_detector(frame)\n",
    "        try:            \n",
    "            min_score = 999       #가장 낮은 점수로 예측된 사람의 점수\n",
    "            min_score_name = \"\"   #가장 높은 점수로 예측된 사람의 이름\n",
    "            \n",
    "            #검출된 사진을 흑백으로 변환 \n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #위에서 학습한 모델로 예측시도\n",
    "            for key, model in models.items():\n",
    "                result = model.predict(face)                \n",
    "                if min_score > result[1]:\n",
    "                    min_score = result[1]\n",
    "                    min_score_name = key\n",
    "                    \n",
    "            #min_score: 신뢰도 0에 가까울수록 정답에 가까움         \n",
    "            if min_score < 500:\n",
    "                \n",
    "                confidence = int(100*(1-(min_score)/300))\n",
    "                # 유사도 화면에 표시 \n",
    "                display_string = str(confidence)+'% Confidence it is ' + min_score_name\n",
    "            cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "            #75 보다 크면 동일 인물로 간주해 UnLocked! \n",
    "            if confidence > 75:\n",
    "                cv2.putText(image, \"Unlocked : \" + min_score_name, (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow('Face Cropper', image)\n",
    "            else:\n",
    "            #75 이하면 타인.. Locked!!! \n",
    "                cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.imshow('Face Cropper', image)\n",
    "        except:\n",
    "            #얼굴 검출 안됨 \n",
    "            cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "            pass\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a425bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276102cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model :lee\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16636\\4027937758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16636\\1995315456.py\u001b[0m in \u001b[0;36mtrains\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model :'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# 학습 시작\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m# 학습이 안되었다면 패스!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16636\\2865262988.py\u001b[0m in \u001b[0;36mtrain_face\u001b[1;34m(user_name)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'face'"
     ]
    }
   ],
   "source": [
    "models = trains()\n",
    "run(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d214a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용안함\n",
    "def main():\n",
    "    LINE_THICKNESS = 2\n",
    "    LINE_COLOR = (255,0,0)\n",
    "    classifier = cv2.CascadeClassifier(\"data/haarcascade_frontalface_default.xml\")\n",
    "    # Set Camera width and height (640 * 480)\n",
    "    camera_width = 640\n",
    "    camera_height = 480\n",
    "    \n",
    "    while True:\n",
    "        option = int(input(\"1: Register\\n2: Detect\\nselect option: \"))\n",
    "       \n",
    "        if option == 1:\n",
    "            user_name = input(\"Input User Name: \").strip()\n",
    "            capture_result, frame = capture()\n",
    "            \n",
    "            if capture_result == 1: \n",
    "                \n",
    "                # Remove Image if there is a file with same name\n",
    "                if os.path.isfile(f\"data/sub_data/{user_name}.png\"):\n",
    "                    os.remove(f\"data/sub_data/{user_name}.png\")\n",
    "                cv2.imwrite(f\"data/sub_data/{user_name}.png\", frame)\n",
    "                img_without_grid = cv2.imread(f\"data/sub_data/{user_name}.png\")\n",
    "                # Track Faces from \n",
    "                faces = track_faces(frame, classifier, 1.1, 3)\n",
    "               \n",
    "                if(len(faces)<1):\n",
    "                    print(\"No Face detected, EXIT\")\n",
    "                    break\n",
    "                # frame, classifier, \n",
    "                for i, (x, y, w, h) in enumerate(faces):\n",
    "                    cv2.rectangle(img_without_grid, (x, y), (x+w,y+h), LINE_COLOR, LINE_THICKNESS)\n",
    "                    cv2.putText(img_without_grid, str(i), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0, 0), 2)\n",
    "                \n",
    "                # Show grid with Numbers\n",
    "                # TODO: SEND THIS TO ANDROID CLIENT\n",
    "                cv2.imshow(\"Enter the grid number you want to save\", img_without_grid)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                grid_number = int(input().strip())\n",
    "                # Assume you got the number from Android Client\n",
    "                # TODO: GET A GRID NUMBER FROM ANDROID CLIENT\n",
    "                \n",
    "                x, y, w, h = faces[grid_number]\n",
    "                print(f'y: {y}, x: {x}')\n",
    "                \n",
    "                # Crop Face and Apply Grayscale \n",
    "                grayscale_face = cv2.cvtColor(img_without_grid[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imwrite(f\"data/sub_data/{user_name}.png\", grayscale_face)\n",
    "#                 cv2.imwrite(f\"data/sub_data/{user_name}.png\", frame)\n",
    "        elif(option == 2):\n",
    "            print(\"Detect From Image\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
