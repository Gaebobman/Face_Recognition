{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "868690a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "# from os import makedirs, listdir\n",
    "# from os.path import isdir, isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787a87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "# function for consecutive capture\n",
    "def detect_face(frame, classifier):\n",
    "    grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = classifier.detectMultiScale(grayscale_frame, 1.3, 5)   # image, image_scale, max_faces\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e9a27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "def capture_face(user_name, classifier):\n",
    "    if not isdir(f\"data/sub_data/{user_name}\"):\n",
    "        makedirs(f\"data/sub_data/{user_name}\")\n",
    "    capture= cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        result, frame = capture.read()\n",
    "        if detect_face(frame, classifier) is not None:\n",
    "            count+=1\n",
    "            face = cv2.resize(detect_face(frame, classifier),(200,200))\n",
    "            # face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imwrite(f\"data/sub_data/{user_name}/{user_name}-{count}.png\",face)\n",
    "            cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),2)\n",
    "            cv2.imshow('Face Cropper',face)\n",
    "        else:\n",
    "            print(\"Face not Found\")\n",
    "            pass\n",
    "        # Press Enter or get 100images to break\n",
    "        if cv2.waitKey(1)==13 or count==5:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Colleting Samples Complete!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bskyvision.com/entry/python-%ED%8A%B9%EC%A0%95-%EC%9D%B8%EB%AC%BC%EC%9D%98-%EC%96%BC%EA%B5%B4%EB%A7%8C-%EA%B2%80%EC%B6%9C%ED%95%98%EA%B8%B0\n",
    "\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "def identify_user(user_name):\n",
    "    path = 'data/sub_data'\n",
    "    user_list = [item for item in os.listdir (path) if os.path.isdir (os.path.join (path, item))]\n",
    "    images = os.listdir('data/sub_data/')\n",
    "    print(images)\n",
    " \n",
    "    # load your image\n",
    "    image_to_be_matched = face_recognition.load_image_file('my_image.jpg')\n",
    " \n",
    "    # encoded the loaded image into a feature vector\n",
    "    image_to_be_matched_encoded = face_recognition.face_encodings(image_to_be_matched)[0]\n",
    " \n",
    "    # iterate over each image\n",
    "    for image in images:\n",
    "        # load the image\n",
    "        current_image = face_recognition.load_image_file(\"images/\" + image)\n",
    "        # encode the loaded image into a feature vector\n",
    "        current_image_encoded = face_recognition.face_encodings(current_image)[0]\n",
    "        # match your image with the image and check if it matches\n",
    "        result = face_recognition.compare_faces(\n",
    "            [image_to_be_matched_encoded], current_image_encoded)\n",
    "        # check if it was a match\n",
    "        if result[0] == True:\n",
    "            print(\"Matched: \" + image)\n",
    "        else:\n",
    "            print(\"Not matched: \" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "745b7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/sub_data'\n",
    "user_list = [item for item in os.listdir (path) if os.path.isdir (os.path.join (path, item))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa526e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jm', 'lee']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "681a5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for user in user_list:\n",
    "    user_images = os.listdir(f'{path}/{user}')\n",
    "    user_images = [f'{user}/{image}' for image in user_images]\n",
    "    images.append(user_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c65745ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jm/jm-1.png', 'jm/jm-2.png', 'jm/jm-3.png', 'jm/jm-4.png', 'jm/jm-5.png'],\n",
       " ['lee/lee-1.png',\n",
       "  'lee/lee-2.png',\n",
       "  'lee/lee-3.png',\n",
       "  'lee/lee-4.png',\n",
       "  'lee/lee-5.png']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e484d720",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2696\\2675927340.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcurrent_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"path/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcurrent_image_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     score = face_recognition.compare_faces([detected_face_encoded], current_image_encoded)? score + 1: score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "score = [0 for i in range(len(user_list))]\n",
    "for image in images:\n",
    "    current_image = face_recognition.load_image_file(\"path/\" + image)\n",
    "    current_image_encoded = face_recognition.face_encodings(current_image)[0]\n",
    "#     score = face_recognition.compare_faces([detected_face_encoded], current_image_encoded)? score + 1: score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e87ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffff83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46883aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edd5af46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colleting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "classifier = cv2.CascadeClassifier(\"data/haarcascade_frontalface_default.xml\")\n",
    "capture_face(\"jm0\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99301390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dd2da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5e414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534758cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#얼굴 검출 (실시간 웹캠)\n",
    "def face_detector(img, size = 0.5):\n",
    "        gray_scale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray_scale,1.3,5)\n",
    "        if len(faces) == 0:\n",
    "            return img,[]\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            roi = cv2.resize(roi, (200,200))\n",
    "        return img,roi   #검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d15eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train User\n",
    "# https://blog.naver.com/chandong83/221695462391\n",
    "\n",
    "def train_face(user_name):\n",
    "    data_path = \"data/sub_data/\" + user_name+ '/'\n",
    "    face_pics = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "    training, labels = [], []\n",
    "    \n",
    "    for i, files in enumerate(face_pics):\n",
    "        image_path = data_path + face_pics[i]\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if images is None:\n",
    "            continue    \n",
    "            \n",
    "        training.append(np.asarray(images, dtype=np.uint8))\n",
    "        labels.append(i)\n",
    "        \n",
    "    if len(labels) == 0:\n",
    "        print(\"There is no data to train.\")\n",
    "        return None\n",
    "    \n",
    "    labels = np.asarray(labels, dtype=np.int32)\n",
    "    # 모델 생성 (Python 4.4.0 이후로 지원 안됨, face_recognition library 사용함)\n",
    "    # https://github.com/ageitgey/face_recognition\n",
    "    # model = cv2.face.LBPHFaceRecognizer_create()\n",
    "    model \n",
    "    \n",
    "    # 학습\n",
    "    model.train(np.asarray(training), np.asarray(labels))\n",
    "    print(name + \" : Model Training Complete!!!!!\")\n",
    "\n",
    "    #학습 모델 리턴\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d6a69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(models):    \n",
    "    #카메라 열기 \n",
    "    capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        #카메라로 부터 사진 한장 읽기 \n",
    "        capture_result, frame = capture.read()\n",
    "        # 얼굴 검출 시도 \n",
    "        image, face = face_detector(frame)\n",
    "        try:            \n",
    "            min_score = 999       #가장 낮은 점수로 예측된 사람의 점수\n",
    "            min_score_name = \"\"   #가장 높은 점수로 예측된 사람의 이름\n",
    "            \n",
    "            #검출된 사진을 흑백으로 변환 \n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #위에서 학습한 모델로 예측시도\n",
    "            for key, model in models.items():\n",
    "                result = model.predict(face)                \n",
    "                if min_score > result[1]:\n",
    "                    min_score = result[1]\n",
    "                    min_score_name = key\n",
    "                    \n",
    "            #min_score: 신뢰도 0에 가까울수록 정답에 가까움         \n",
    "            if min_score < 500:\n",
    "                \n",
    "                confidence = int(100*(1-(min_score)/300))\n",
    "                # 유사도 화면에 표시 \n",
    "                display_string = str(confidence)+'% Confidence it is ' + min_score_name\n",
    "            cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
    "            #75 보다 크면 동일 인물로 간주해 UnLocked! \n",
    "            if confidence > 75:\n",
    "                cv2.putText(image, \"Unlocked : \" + min_score_name, (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.imshow('Face Cropper', image)\n",
    "            else:\n",
    "            #75 이하면 타인.. Locked!!! \n",
    "                cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.imshow('Face Cropper', image)\n",
    "        except:\n",
    "            #얼굴 검출 안됨 \n",
    "            cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "            pass\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
